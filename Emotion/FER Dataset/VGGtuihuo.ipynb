{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def extract_dataset(main_folder, image_size=(48, 48)):\n",
    "    train_dataset = []\n",
    "    train_labels = []\n",
    "    val_dataset = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Define a dictionary to map each emotion to a unique label\n",
    "    emotion_labels = {'neutral': 0, 'happy': 1, 'angry': 2, 'surprise': 3, 'sad': 4}\n",
    "\n",
    "    # Loop through emotions in the main folder\n",
    "    for emotion in emotion_labels:\n",
    "        train_folder = os.path.join(main_folder, 'train', emotion)\n",
    "        val_folder = os.path.join(main_folder, 'validation', emotion)\n",
    "        label = emotion_labels[emotion]\n",
    "\n",
    "        # Training set\n",
    "        for filename in os.listdir(train_folder):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
    "                image_path = os.path.join(train_folder, filename)\n",
    "\n",
    "                # Load the image using TensorFlow and convert to grayscale\n",
    "                img = load_img(image_path, color_mode='grayscale', target_size=image_size)\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # Normalize the pixel values to the range [0, 1]\n",
    "                img_array /= 255.0\n",
    "\n",
    "                # Append the image data and label to the training dataset\n",
    "                train_dataset.append(img_array)\n",
    "                train_labels.append(label)\n",
    "\n",
    "        # Validation set\n",
    "        for filename in os.listdir(val_folder):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
    "                image_path = os.path.join(val_folder, filename)\n",
    "\n",
    "                # Load the image using TensorFlow and convert to grayscale\n",
    "                img = load_img(image_path, color_mode='grayscale', target_size=image_size)\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # Normalize the pixel values to the range [0, 1]\n",
    "                img_array /= 255.0\n",
    "\n",
    "                # Append the image data to the validation dataset\n",
    "                val_dataset.append(img_array)\n",
    "                val_labels.append(label)\n",
    "\n",
    "    # Convert datasets to numpy arrays\n",
    "    train_dataset = np.array(train_dataset)\n",
    "    train_labels = np.array(train_labels)\n",
    "    val_dataset = np.array(val_dataset)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    # One-hot encode the labels\n",
    "    one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "    train_labels = one_hot_encoder.fit_transform(train_labels.reshape(-1, 1))\n",
    "    val_labels = one_hot_encoder.transform(val_labels.reshape(-1, 1))\n",
    "\n",
    "    return train_dataset, train_labels, val_dataset, val_labels\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "def create_vggnet16_model(input_shape=(48, 48, 1)):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model_with_simulated_annealing(model, train_dataset, train_labels, val_dataset, val_labels, initial_temp=1000, cooling_rate=0.003, max_iter=1000):\n",
    "    # 编译模型\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    history = model.fit(train_dataset, train_labels, epochs=20, batch_size=64, validation_data=(val_dataset, val_labels), callbacks=[early_stopping])\n",
    "\n",
    "    # 模拟退火算法优化模型参数\n",
    "    current_temp = initial_temp\n",
    "    current_weights = model.get_weights()\n",
    "    best_weights = current_weights\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # 随机扰动权重\n",
    "        new_weights = [w + np.random.normal(0, 1, w.shape) for w in current_weights]\n",
    "        model.set_weights(new_weights)\n",
    "\n",
    "        # 计算新的损失\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(train_dataset, train_labels, epochs=1, batch_size=64, verbose=0, validation_data=(val_dataset, val_labels))\n",
    "        new_loss = history.history['val_loss'][0]\n",
    "\n",
    "        # 判断是否接受新权重\n",
    "        if new_loss < best_loss:\n",
    "            best_loss = new_loss\n",
    "            best_weights = new_weights\n",
    "        else:\n",
    "            acceptance_prob = np.exp((best_loss - new_loss) / current_temp)\n",
    "            if np.random.rand() < acceptance_prob:\n",
    "                best_loss = new_loss\n",
    "                best_weights = new_weights\n",
    "\n",
    "        # 降温\n",
    "        current_temp *= (1 - cooling_rate)\n",
    "\n",
    "    model.set_weights(best_weights)\n",
    "\n",
    "    return model, history\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "def evaluate_model(model, val_dataset, val_labels, emotion_labels):\n",
    "    # 模型评估\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, val_labels)\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "    print(f'Validation accuracy: {val_accuracy}')\n",
    "\n",
    "    # 预测验证集\n",
    "    val_predictions = model.predict(val_dataset)\n",
    "    val_pred_classes = np.argmax(val_predictions, axis=1)\n",
    "    val_true_classes = np.argmax(val_labels, axis=1)\n",
    "\n",
    "    # 分类报告\n",
    "    report = classification_report(val_true_classes, val_pred_classes, target_names=emotion_labels.keys())\n",
    "    print(report)\n",
    "\n",
    "    # 混淆矩阵\n",
    "    conf_matrix = confusion_matrix(val_true_classes, val_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=emotion_labels.keys(), yticklabels=emotion_labels.keys())\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC曲线和AUC\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, emotion in enumerate(emotion_labels.keys()):\n",
    "        fpr, tpr, _ = roc_curve(val_labels[:, i], val_predictions[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{emotion} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # 损失和准确率图像\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "F:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m582s\u001B[0m 2s/step - accuracy: 0.3696 - loss: 6.3679 - val_accuracy: 0.2164 - val_loss: 5.9336\n",
      "Epoch 2/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m580s\u001B[0m 2s/step - accuracy: 0.5432 - loss: 5.0645 - val_accuracy: 0.5752 - val_loss: 4.6921\n",
      "Epoch 3/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m571s\u001B[0m 2s/step - accuracy: 0.6139 - loss: 4.5234 - val_accuracy: 0.5968 - val_loss: 4.2810\n",
      "Epoch 4/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m567s\u001B[0m 1s/step - accuracy: 0.6721 - loss: 4.0296 - val_accuracy: 0.6098 - val_loss: 3.9006\n",
      "Epoch 5/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m569s\u001B[0m 2s/step - accuracy: 0.7201 - loss: 3.5704 - val_accuracy: 0.6274 - val_loss: 3.5724\n",
      "Epoch 6/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m568s\u001B[0m 2s/step - accuracy: 0.7625 - loss: 3.1680 - val_accuracy: 0.6474 - val_loss: 3.2802\n",
      "Epoch 7/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m567s\u001B[0m 1s/step - accuracy: 0.8132 - loss: 2.7924 - val_accuracy: 0.6583 - val_loss: 3.0383\n",
      "Epoch 8/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 1s/step - accuracy: 0.8581 - loss: 2.4584 - val_accuracy: 0.6607 - val_loss: 2.8716\n",
      "Epoch 9/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m567s\u001B[0m 1s/step - accuracy: 0.8899 - loss: 2.1883 - val_accuracy: 0.6474 - val_loss: 2.8370\n",
      "Epoch 10/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m568s\u001B[0m 2s/step - accuracy: 0.9235 - loss: 1.9604 - val_accuracy: 0.6335 - val_loss: 2.8063\n",
      "Epoch 11/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m566s\u001B[0m 1s/step - accuracy: 0.9380 - loss: 1.7916 - val_accuracy: 0.6525 - val_loss: 2.7160\n",
      "Epoch 12/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 1s/step - accuracy: 0.9467 - loss: 1.6553 - val_accuracy: 0.6507 - val_loss: 2.7380\n",
      "Epoch 13/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 1s/step - accuracy: 0.9563 - loss: 1.5370 - val_accuracy: 0.6494 - val_loss: 2.7172\n",
      "Epoch 14/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m566s\u001B[0m 1s/step - accuracy: 0.9557 - loss: 1.4711 - val_accuracy: 0.6515 - val_loss: 2.6709\n",
      "Epoch 15/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m569s\u001B[0m 2s/step - accuracy: 0.9621 - loss: 1.4006 - val_accuracy: 0.6563 - val_loss: 2.6631\n",
      "Epoch 16/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m566s\u001B[0m 1s/step - accuracy: 0.9646 - loss: 1.3383 - val_accuracy: 0.6514 - val_loss: 2.7428\n",
      "Epoch 17/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m570s\u001B[0m 2s/step - accuracy: 0.9695 - loss: 1.2847 - val_accuracy: 0.6512 - val_loss: 2.7156\n",
      "Epoch 18/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m568s\u001B[0m 2s/step - accuracy: 0.9555 - loss: 1.2881 - val_accuracy: 0.6413 - val_loss: 2.7459\n",
      "Epoch 19/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m565s\u001B[0m 1s/step - accuracy: 0.9624 - loss: 1.2439 - val_accuracy: 0.6472 - val_loss: 2.6442\n",
      "Epoch 20/20\n",
      "\u001B[1m378/378\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m566s\u001B[0m 1s/step - accuracy: 0.9671 - loss: 1.2116 - val_accuracy: 0.6415 - val_loss: 2.7916\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m model \u001B[38;5;241m=\u001B[39m create_vggnet16_model()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 使用模拟退火算法训练模型\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m trained_model, history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model_with_simulated_annealing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 评估训练好的模型\u001B[39;00m\n\u001B[0;32m     14\u001B[0m emotion_labels \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneutral\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhappy\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mangry\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurprise\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m3\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msad\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m4\u001B[39m}\n",
      "Cell \u001B[1;32mIn[30], line 65\u001B[0m, in \u001B[0;36mtrain_model_with_simulated_annealing\u001B[1;34m(model, train_dataset, train_labels, val_dataset, val_labels, initial_temp, cooling_rate, max_iter)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# 计算新的损失\u001B[39;00m\n\u001B[0;32m     64\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 65\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m new_loss \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# 判断是否接受新权重\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[0;32m    322\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 323\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    324\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[0;32m    325\u001B[0m         step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[0;32m    326\u001B[0m     )\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:918\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m   \u001B[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001B[39;00m\n\u001B[0;32m    913\u001B[0m   filtered_flat_args \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    914\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(\n\u001B[0;32m    915\u001B[0m           bound_args\n\u001B[0;32m    916\u001B[0m       )\n\u001B[0;32m    917\u001B[0m   )\n\u001B[1;32m--> 918\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_concrete_variable_creation_fn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    919\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_concrete_variable_creation_fn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfn_with_cond\u001B[39m(inner_args, inner_kwds):\n\u001B[0;32m    924\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32mF:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 设置数据集文件夹路径和图像尺寸大小\n",
    "main_folder_path = 'dataset'\n",
    "image_size = (48, 48)\n",
    "\n",
    "# 提取数据集\n",
    "train_dataset, train_labels, val_dataset, val_labels = extract_dataset(main_folder_path, image_size=image_size)\n",
    "\n",
    "# 使用预定义模型\n",
    "model = create_vggnet16_model()\n",
    "# 使用模拟退火算法训练模型\n",
    "trained_model, history = train_model_with_simulated_annealing(model, train_dataset, train_labels, val_dataset, val_labels)\n",
    "\n",
    "# 评估训练好的模型\n",
    "emotion_labels = {'neutral': 0, 'happy': 1, 'angry': 2, 'surprise': 3, 'sad': 4}\n",
    "evaluate_model(trained_model, val_dataset, val_labels, emotion_labels)\n",
    "\n",
    "# 保存训练好的模型\n",
    "trained_model.save('trained_model_with_simulated_annealing.h5')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
